<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MDE in the era of Generative AI</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            background-color: #FFFFFF;
            color: #FFA500;
            line-height: 1.6;
            padding: 20px;
            margin: 0;
        }
        @keyframes slideIn {
          0% {
            transform: translateY(-100%);
            opacity: 0;
          }
          100% {
            transform: translateY(0);
            opacity: 1;
          }
        }
        
        .animated-title {
          animation: slideIn 1s ease-out forwards;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            text-align: center;
        }
        h1, h2, h3 {
            color: #FFA500;
        }
        .authors {
            color: #000000;
            font-style: italic;
            margin-bottom: 10px;
        }
        .affiliations {
            color: #000000;
            font-size: 0.9em;
            margin-bottom: 20px;
        }
        .buttons {
            margin: 20px 0;
        }
        .button {
            display: inline-block;
            padding: 10px 20px;
            background-color: #FFA500;
            color: #000000;
            text-decoration: none;
            margin: 5px;
            border-radius: 5px;
        }
        .video-container {
            position: relative;
            width: 80%;
            max-width: 560px;
            margin: 30px auto;
        }
        .video-container::before {
            content: "";
            display: block;
            padding-top: 56.25%;
        }
        .video-container iframe {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }
        .description {
            text-align: left;
            background-color: #FFFFFF;
            color: #000000;
            padding: 20px;
            border-radius: 5px;
            margin-top: 30px;
        }
        .description table {
            width: 70%;
            border-collapse: collapse;
            margin-top: 15px;
        }
        
        .description th, .description td {
            border: 1px solid ;
            padding: 8px;
            text-align: left;
        }
        

    </style>
</head>
<body>
    <div class="container">
        <h1 class="animated-title">MDE in the era of Generative AI/h1>


        <div class="authors">
             Ahmed ALAOUI MDAGHRI<sup>1,2</sup>, Meriem OUEDERNI<sup>2</sup>, Lotfi CHAARI<sup>2</sup>
        </div>
        <div class="affiliations">
            1: [Nantes University], 2: [IRIT]
        </div>
        <div class="buttons">
            <a href="https://www.youtube.com/watch?v=qBBrs1-Rz6A&t=3s" class="button">YouTube</a>
            <a href="https://verymadsoul-ecore-gen.hf.space" class="button">HF Space</a>
            <a href="https://github.com/AlaouiMdaghriAhmed/Ecore-Gen" class="button">Github</a>
            
        </div>
        <!-- Add more content about your paper here -->
    </div>
    <div align="center">
        <iframe width="560" height="315" src="https://www.youtube.com/embed/qBBrs1-Rz6A" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
    </div>
    
    <div class="description">
            <h3>Acknowledgment</h3>
                <p>This work is supported and funded by IBCO-CIMI-CNRS research project (call 2021-2024).</p>
            <h3>Description</h3>
            <p>
                We introduce LLM4MDE: a novel approach that combines in context learning and iterative
                prompting for program verification to ensure programs written in domain-specific
                languages are syntactically valid and incorporate environment constraints.
            </p>
            <h3>Main System Design</h3>
            <ol>
        <li><strong>Specific Prompt:</strong>
            <p>Our solution starts with an input prompt holding two parameters:</p>
            <ul>
                <li>The Natural Language Description (NLD) of a future DSL including user requirements and semantics' constraints</li>
                <li>Document type definition on a specific modelling language (e.g., Ecore definition file)</li>
            </ul>
            <p>We combine multiple prompting techniques: grammar prompting, Chain-of-Thought (COT), and tool use, to increase prompting quality.</p>
        </li>
        
        <li><strong>Output Generation:</strong>
            <p>The LLM processes the input prompt to generate the serialized result (in XMI format) by LLM inference. For Ecore meta-model as target output, the inference:</p>
            <ul>
                <li>Parses Ecore language markers</li>
                <li>Extracts relevant concepts, entities, attributes, and relationships</li>
                <li>Builds structural model adhering to Ecore syntax</li>
            </ul>
        </li>
        
        <li><strong>Model Validation:</strong>
            <p>The process involves:</p>
            <ul>
                <li>Parsing using domain grammar to check for syntactic errors</li>
                <li>Human intervention for semantics checking if no syntactic errors are found</li>
                <li>Iterative prompting with LLM agents to fix syntactic errors if present</li>
            </ul>
        </li>
        
        <li><strong>Database Storage for Use Cases:</strong>
            <p>Validated outputs are stored in a database for further analysis and fine-tuning of the LLM, facilitating iterative refinement based on feedback and real-world scenarios.</p>
        </li>
        
        <li><strong>Ambiguity Resolution:</strong>
            <p>For unresolved ambiguities or validation failures, we re-prompt the LLM with:</p>
            <ul>
                <li>The occurred errors</li>
                <li>Possible additional description from the user</li>
                <li>Access to external tools (e.g., API search calls, documentation) to enhance understanding</li>
            </ul>
        </li>
        
        <li><strong>Fine-tuning and Model Improvements:</strong>
            <p>Validated results that were stored are used to fine-tune our LLMs after gathering sufficient validated models.</p>
        </li>
    </ol>
            <h3> Distribution of one use case resolution</h3>
            <p>
        The following table depicts the distribution of use case resolutions for each model. 
        These statistics were collected based on the resolution rate of one use case (SimplePDL use case) over 40 iterations by our top-performing models.
    </p>
    <table>
        <tr>
            <th>Model</th>
            <th>Context provided</th>
            <th>Correct output</th>
            <th>N</th>
        </tr>
        <tr>
            <td rowspan="3">GPT-4o</td>
            <td>Zero-Shot</td>
            <td>0</td>
            <td>40</td>
        </tr>
        <tr>
            <td>Our prompt</td>
            <td>2</td>
            <td>40</td>
        </tr>
        <tr>
            <td>Iterative Prompting</td>
            <td>32</td>
            <td>40</td>
        </tr>
        <tr>
            <td rowspan="3">meta-llama/Meta-Llama-3-70B-Instruct</td>
            <td>Zero-Shot</td>
            <td>0</td>
            <td>40</td>
        </tr>
        <tr>
            <td>Our Prompt</td>
            <td>21</td>
            <td>40</td>
        </tr>
        <tr>
            <td>Iterative Prompting</td>
            <td>30</td>
            <td>40</td>
        </tr>
        <tr>
            <td rowspan="3">mistralai/Mixtral-8x7B-Instruct-v0.1</td>
            <td>Zero-Shot</td>
            <td>0</td>
            <td>40</td>
        </tr>
        <tr>
            <td>Our Prompt</td>
            <td>8</td>
            <td>40</td>
        </tr>
        <tr>
            <td>Iterative Prompting</td>
            <td>18</td>
            <td>40</td>
        </tr>
    </table>
            <h3>Fine-Tuning Job</h3>

            <p>To improve our model's performance, we conducted a fine-tuning process:</p>
            <ul>
                <li><strong>Data Simulation:</strong> We synthetically generated textual representations of Ecore files to create a training and validation dataset.</li>
                <li><strong>Data Collection:</strong> We web-scraped 200 .ecore files from GitHub and reverse-engineered them into natural language descriptions.</li>
                <li><strong>Data Formatting:</strong> We followed OpenAI's documentation to format the data for instruct-type models.</li>
                <li><strong>Fine-Tuning:</strong> Due to availabilty, we only fine-tune GPT-3.5-Turbo.</li>
                <li><strong>Performance Evaluation:</strong> We compared the performance of different models alongside the fine-tuned model:
                    <table>
                        <tr>
                            <th>Model</th>
                            <th>Context</th>
                            <th>Correct Output</th>
                            <th>Similarity</th>
                        </tr>
                        <tr>
                            <td rowspan="3">GPT-4o</td>
                            <td>Zero-Shot</td>
                            <td>0</td>
                            <td>0.414</td>
                        </tr>
                        <tr>
                            <td>Our prompt</td>
                            <td>0</td>
                            <td>0.6183</td>
                        </tr>
                        <tr>
                            <td>Iterative Prompting</td>
                            <td>0.18</td>
                            <td>0.7041</td>
                        </tr>
                        <tr>
                            <td rowspan="3">GPT-3.5-Turbo</td>
                            <td>Zero-Shot</td>
                            <td>0</td>
                            <td>0.0589</td>
                        </tr>
                        <tr>
                            <td>Our Prompt</td>
                            <td>0.02</td>
                            <td>0.6825</td>
                        </tr>
                        <tr>
                            <td>Iterative Prompting</td>
                            <td>0.02</td>
                            <td>0.5845</td>
                        </tr>
                        <tr>
                            <td>Fine-tuned GPT-3.5-Turbo</td>
                            <td>Zero-Shot</td>
                            <td>0.16</td>
                            <td>0.7807</td>
                        </tr>
                    </table>
                </li>
            </ul>
    </div>
    <div align="center">
        <h3>Demo Application</h3>
        <iframe
    	src="https://verymadsoul-ecore-gen.hf.space"
    	frameborder="0"
    	width="1200"
    	height="450"></iframe>
    </div>
<script>
  document.addEventListener('DOMContentLoaded', (event) => {
    document.querySelector('.animated-title').style.opacity = '0';
    setTimeout(() => {
      document.querySelector('.animated-title').style.opacity = '1';
    }, 100);
  });
</script>
</body>
</html>

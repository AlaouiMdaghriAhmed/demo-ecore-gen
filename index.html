<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MDE in the era of Generative AI</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            background-color: #FFFFFF;
            color: #FFA500;
            line-height: 1.6;
            padding: 20px;
            margin: 0;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            text-align: center;
        }
        h1, h2, h3 {
            color: #FFA500;
        }
        .authors {
            color: #000000;
            font-style: italic;
            margin-bottom: 10px;
        }
        .affiliations {
            color: #000000;
            font-size: 0.9em;
            margin-bottom: 20px;
        }
        .buttons {
            margin: 20px 0;
        }
        .button {
            display: inline-block;
            padding: 10px 20px;
            background-color: #FFA500;
            color: #000000;
            text-decoration: none;
            margin: 5px;
            border-radius: 5px;
        }
        .video-container {
            position: relative;
            width: 80%;
            max-width: 560px;
            margin: 30px auto;
        }
        .video-container::before {
            content: "";
            display: block;
            padding-top: 56.25%;
        }
        .video-container iframe {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }
        .description {
            text-align: left;
            background-color: #FFFFFF;
            color: #000000;
            padding: 20px;
            border-radius: 5px;
            margin-top: 30px;
        }
        .description table {
            width: 70%;
            border-collapse: collapse;
            margin-top: 15px;
        }
        
        .description th, .description td {
            border: 1px solid ;
            padding: 8px;
            text-align: left;
        }
        

    </style>
</head>
<body>
    <div class="container">
        <h1>MDE in the era of Generative AI</h1>
        <div class="authors">
            [Ahmed ALAOUI MDAGHRI], [Meriem OUEDERNI], [Lotfi CHAARI]
        </div>
        <div class="affiliations">
            1: [Nantes University], 2: [IRIT], ...
        </div>
        <div class="buttons">
            <a href="https://www.youtube.com/watch?v=qBBrs1-Rz6A&t=3s" class="button">YouTube</a>
            <a href="" class="button">GitHub</a>
        </div>
        <!-- Add more content about your paper here -->
    </div>
    <div align="center">
        <iframe width="560" height="315" src="https://www.youtube.com/embed/qBBrs1-Rz6A" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
    </div>
    <div class="description">
            <h3>Description</h3>
            <p>
                We introduce LLM4MDE: a novel approach that combines in context learning and iterative
                prompting for program verification to ensure programs written in domain-specific
                languages are syntactically valid and incorporate environment constraints.
            </p>
            <h3>Main System Design</h3>
            <ol>
                <li><strong>Input Prompt and NLD:</strong> Our solution begins with an input prompt containing the natural language description along with syntactic and semantic constraints, providing essential information for model generation. For our prompt we couple many prompting techniques; similar to grammar prompting, also COT and tool use.</li>
                
                <li><strong>Ecore Model Generation:</strong> The LLM processes the input prompt and specification sheet to generate an Ecore model by LLM inference. After parsing the technical file markers and extracting relevant concepts, entities, attributes, and relationships, the LLM builds a structured model adhering to the Ecore format.</li>
                
                <li><strong>Model Validation:</strong> Initially, a meta-model is created based on the NLD. This model is then parsed using the domain grammar to check for syntactic errors. If no errors are found, the process terminates. However, if syntactic errors are detected, the algorithm iteratively addresses each error. For each identified error, the meta-model along with the error details are passed to a LLM. The LLM is then prompted to suggest fixes for these errors. The meta-model is updated with the suggested corrections, and the parsing process is repeated. This cycle continues until the meta-model is free of syntactic errors, ensuring a validated and syntactically correct meta-model.</li>
                
                <li><strong>Database Storage for Use Cases:</strong> Validated models are stored in a database for further analysis and fine-tuning of the LLM. This repository of use cases facilitates iterative refinement of the model, enabling continuous improvement based on feedback and real-world application scenarios.</li>
                
                <li><strong>Iterative Reasoning for Ambiguity Resolution:</strong> In cases where the generated model fails the validation step or encounters ambiguity, our solution employs iterative prompting. This iterative process involves reprompting the LLM with a prompt coupled with the occurring error, enabling it to revisit and refine its understanding of the domain context. Additionally, access to external tools such as API search calls and documentation enhances the LLM's comprehension and resolution of ambiguous requests.</li>
                
                <li><strong>Fine-tuning and model improvements:</strong> After correcting the generate model based on iterative reasoning and additional inputs, the validated results get stored and after gathering enough validated models, we can use them to fine-tune our LLMs.</li>
            </ol>
            <h3> Distribution of one use case resolution</h3>
            <p>
        The following table depicts the distribution of use case resolutions for each model. 
        These statistics were collected based on the resolution rate of one use case over 40 iterations by our top-performing models.
    </p>
    <table>
        <tr>
            <th>Model</th>
            <th>Context provided</th>
            <th>Correct output</th>
            <th>N</th>
        </tr>
        <tr>
            <td rowspan="3">GPT-4o</td>
            <td>Zero-Shot</td>
            <td>0</td>
            <td>40</td>
        </tr>
        <tr>
            <td>Our prompt</td>
            <td>2</td>
            <td>40</td>
        </tr>
        <tr>
            <td>Iterative Prompting</td>
            <td>32</td>
            <td>40</td>
        </tr>
        <tr>
            <td rowspan="3">meta-llama/Meta-Llama-3-70B-Instruct</td>
            <td>Zero-Shot</td>
            <td>0</td>
            <td>40</td>
        </tr>
        <tr>
            <td>Our Prompt</td>
            <td>21</td>
            <td>40</td>
        </tr>
        <tr>
            <td>Iterative Prompting</td>
            <td>30</td>
            <td>40</td>
        </tr>
        <tr>
            <td rowspan="3">mistralai/Mixtral-8x7B-Instruct-v0.1</td>
            <td>Zero-Shot</td>
            <td>0</td>
            <td>40</td>
        </tr>
        <tr>
            <td>Our Prompt</td>
            <td>8</td>
            <td>40</td>
        </tr>
        <tr>
            <td>Iterative Prompting</td>
            <td>18</td>
            <td>40</td>
        </tr>
    </table>
            <h3>Fine-Tuning Job</h3>

            <p>To improve our model's performance, we conducted a fine-tuning process:</p>
            <ul>
                <li><strong>Data Simulation:</strong> We synthetically generated textual representations of Ecore files to create a training and validation dataset.</li>
                <li><strong>Data Collection:</strong> We web-scraped 200 .ecore files from GitHub and reverse-engineered them into natural language descriptions.</li>
                <li><strong>Data Formatting:</strong> We followed OpenAI's documentation to format the data for instruct-type models.</li>
                <li><strong>Fine-Tuning:</strong> Due to limitations, we fine-tuned GPT-3.5-Turbo instead of GPT-4o.</li>
                <li><strong>Performance Evaluation:</strong> We compared the performance of different models:
                    <table>
                        <tr>
                            <th>Model</th>
                            <th>Context</th>
                            <th>Correct Output</th>
                            <th>Similarity</th>
                        </tr>
                        <tr>
                            <td rowspan="3">GPT-4o</td>
                            <td>Zero-Shot</td>
                            <td>0</td>
                            <td>0.414</td>
                        </tr>
                        <tr>
                            <td>Our prompt</td>
                            <td>0</td>
                            <td>0.6183</td>
                        </tr>
                        <tr>
                            <td>Iterative Prompting</td>
                            <td>0.18</td>
                            <td>0.7041</td>
                        </tr>
                        <tr>
                            <td rowspan="3">GPT-3.5-Turbo</td>
                            <td>Zero-Shot</td>
                            <td>0</td>
                            <td>0.0589</td>
                        </tr>
                        <tr>
                            <td>Our Prompt</td>
                            <td>0.02</td>
                            <td>0.6825</td>
                        </tr>
                        <tr>
                            <td>Iterative Prompting</td>
                            <td>0.02</td>
                            <td>0.5845</td>
                        </tr>
                        <tr>
                            <td>Fine-tuned GPT-3.5-Turbo</td>
                            <td>Zero-Shot</td>
                            <td>0.16</td>
                            <td>0.7807</td>
                        </tr>
                    </table>
                </li>
            </ul>
    </div>
    <div align="center">
        <h3>Demo Application</h3>
        <iframe
    	src="https://verymadsoul-ecore-gen.hf.space"
    	frameborder="0"
    	width="1200"
    	height="450"></iframe>
    </div>

</body>
</html>
